{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use matrix factorization for recommender system\n",
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parametter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=60 # latent factors\n",
    "lam=0.02 # regularization\n",
    "learning_rate=0.001 # learning rate\n",
    "max_iter=20 # max iterations\n",
    "print_every=1 # print loss for each iteration\n",
    "tolerance=1e-6 # tolerance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create class MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MFOptimized:\n",
    "    def __init__(self, Y, K, lam=0.1, learning_rate=0.01, max_iter=100, print_every=10, tolerance=1e-6):\n",
    "        \"\"\"\n",
    "        Initialize the MF model.\n",
    "        Y: numpy array, shape (n_ratings, 3), each row [user_id, item_id, rating].\n",
    "        K: Number of latent factors.\n",
    "        lam: Regularization parameter.\n",
    "        learning_rate: Learning rate for gradient descent.\n",
    "        max_iter: Number of training iterations.\n",
    "        print_every: Print loss every print_every iterations.\n",
    "        tolerance: Tolerance for convergence based on change in loss.\n",
    "        \"\"\"\n",
    "        self.Y = Y\n",
    "        self.K = K\n",
    "        self.lam = lam\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.print_every = print_every\n",
    "        self.tolerance = tolerance  # Tolerance for convergence\n",
    "\n",
    "        # Initialize user and item dimensions\n",
    "        self.n_users = int(np.max(Y[:, 0]) + 1)\n",
    "        self.n_items = int(np.max(Y[:, 1]) + 1)\n",
    "\n",
    "        # Initialize latent factors and biases\n",
    "        self.H = np.random.normal(0, 0.1, (self.n_users, K)).astype(np.float32)  # Latent factors for users\n",
    "        self.Q = np.random.normal(0, 0.1, (self.n_items, K)).astype(np.float32)  # Latent factors for items\n",
    "        self.o = np.zeros(self.n_users, dtype=np.float32)  # Biases for users\n",
    "        self.p = np.zeros(self.n_items, dtype=np.float32)  # Biases for items\n",
    "        self.mu = np.mean(Y[:, 2])  # Global average rating\n",
    "\n",
    "    def compute_loss(self):\n",
    "        \"\"\"\n",
    "        Compute the loss based on the provided formula.\n",
    "        \"\"\"\n",
    "        n_ratings = self.Y.shape[0]\n",
    "        error_sum = 0\n",
    "        regularization_sum = 0\n",
    "\n",
    "        for n in range(n_ratings):\n",
    "            u, i, r = int(self.Y[n, 0]), int(self.Y[n, 1]), self.Y[n, 2]\n",
    "            pred = self.o[u] + self.p[i] + self.mu + np.dot(self.H[u], self.Q[i])\n",
    "            error = r - pred\n",
    "            error_sum += error ** 2\n",
    "            regularization_sum += np.sum(self.H[u] ** 2) + np.sum(self.Q[i] ** 2) + self.o[u] ** 2 + self.p[i] ** 2\n",
    "\n",
    "        # Compute total loss\n",
    "        loss = 0.5 * error_sum / n_ratings + 0.5 * self.lam * regularization_sum\n",
    "        return loss\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Train the model using stochastic gradient descent (SGD).\n",
    "        \"\"\"\n",
    "        prev_loss = float('inf')\n",
    "\n",
    "        for it in range(self.max_iter):\n",
    "            np.random.shuffle(self.Y)  # Shuffle the data at the start of each epoch\n",
    "\n",
    "            for n in range(self.Y.shape[0]):\n",
    "                u, i, r = int(self.Y[n, 0]), int(self.Y[n, 1]), self.Y[n, 2]\n",
    "                \n",
    "                # Calculate prediction\n",
    "                pred = self.o[u] + self.p[i] + self.mu + np.dot(self.H[u], self.Q[i])\n",
    "\n",
    "                # Calculate error\n",
    "                error = r - pred\n",
    "\n",
    "                # Update latent factors and biases\n",
    "                self.H[u] += self.learning_rate * (error * self.Q[i] - self.lam * self.H[u])\n",
    "                self.Q[i] += self.learning_rate * (error * self.H[u] - self.lam * self.Q[i])\n",
    "\n",
    "                self.o[u] += self.learning_rate * (error - self.lam * self.o[u])\n",
    "                self.p[i] += self.learning_rate * (error - self.lam * self.p[i])\n",
    "\n",
    "            # Compute current loss and check for convergence\n",
    "            loss = self.compute_loss()\n",
    "\n",
    "            # Check if the change in loss is smaller than the tolerance\n",
    "            if abs(prev_loss - loss) < self.tolerance:\n",
    "                print(f\"Convergence reached at iteration {it + 1}\")\n",
    "                break\n",
    "\n",
    "            prev_loss = loss\n",
    "\n",
    "            # Print loss every 'print_every' iterations\n",
    "            if (it + 1) % self.print_every == 0:\n",
    "                print(f\"Iteration {it + 1}/{self.max_iter}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict(self, u, i):\n",
    "        \"\"\"\n",
    "        Predict the rating for a specific user-item pair.\n",
    "        \"\"\"\n",
    "        u, i = int(u), int(i)\n",
    "        pred = self.o[u] + self.p[i] + self.mu + np.dot(self.H[u], self.Q[i])\n",
    "        return np.clip(pred, 0, 5)\n",
    "\n",
    "    def evaluate_rmse(self, test_data):\n",
    "        \"\"\"\n",
    "        Compute RMSE on the test set.\n",
    "        \"\"\"\n",
    "        n_tests = test_data.shape[0]\n",
    "        squared_error = 0\n",
    "        for n in range(n_tests):\n",
    "            pred = self.predict(test_data[n, 0], test_data[n, 1])\n",
    "            squared_error += (pred - test_data[n, 2]) ** 2\n",
    "        rmse = np.sqrt(squared_error / n_tests)\n",
    "        return rmse\n",
    "    \n",
    "    def export_latent_matrices_and_biases(self, output_dir=\"data/output\"):\n",
    "        \"\"\"\n",
    "        Export the latent matrices (H, Q) and biases (o, p) to CSV files.\n",
    "        Args:\n",
    "            output_dir (str): Directory where the files will be saved.\n",
    "        \"\"\"\n",
    "        os.makedirs(output_dir, exist_ok=True)  # Create the output directory if it doesn't exist\n",
    "\n",
    "        # Save user latent factors (H)\n",
    "        np.savetxt(os.path.join(output_dir, \"user_latent_factors.csv\"), self.H, delimiter=\",\")\n",
    "        print(f\"User latent factors saved to {os.path.join(output_dir, 'user_latent_factors.csv')}\")\n",
    "\n",
    "        # Save item latent factors (Q)\n",
    "        np.savetxt(os.path.join(output_dir, \"item_latent_factors.csv\"), self.Q, delimiter=\",\")\n",
    "        print(f\"Item latent factors saved to {os.path.join(output_dir, 'item_latent_factors.csv')}\")\n",
    "\n",
    "        # Save user biases (o)\n",
    "        np.savetxt(os.path.join(output_dir, \"user_biases.csv\"), self.o, delimiter=\",\")\n",
    "        print(f\"User biases saved to {os.path.join(output_dir, 'user_biases.csv')}\")\n",
    "\n",
    "        # Save item biases (p)\n",
    "        np.savetxt(os.path.join(output_dir, \"item_biases.csv\"), self.p, delimiter=\",\")\n",
    "        print(f\"Item biases saved to {os.path.join(output_dir, 'item_biases.csv')}\")\n",
    "\n",
    "        # Save global mean (mu)\n",
    "        with open(os.path.join(output_dir, \"global_mean.txt\"), \"w\") as f:\n",
    "            f.write(str(self.mu))\n",
    "        print(f\"Global mean saved to {os.path.join(output_dir, 'global_mean.txt')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the results\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_path = '../data/ml-latest-small/ratings.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "data = data.rename(columns={'userId': 'user_id', 'movieId': 'movie_id'})\n",
    "data = data[['user_id', 'movie_id', 'rating']]\n",
    "\n",
    "# Split data into train and test\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "rate_train = train_data.to_numpy()\n",
    "rate_test = test_data.to_numpy()\n",
    "\n",
    "# Adjust indices to be 0-based\n",
    "rate_train[:, :2] -= 1\n",
    "rate_test[:, :2] -= 1\n",
    "\n",
    "# Train the model\n",
    "mf = MFOptimized(rate_train, K, lam, learning_rate, max_iter, print_every, tolerance)\n",
    "mf.fit()\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = mf.evaluate_rmse(rate_test)\n",
    "print(f\"\\nOptimized MF, RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a prediction for a user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions_for_user(model, user_id, n_items):\n",
    "    predictions = [(user_id + 1, item + 1, model.predict(user_id, item)) for item in range(n_items)]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make comparision of real ratings and model's predicted ratings for a user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_csv(model, user_id, data, n_items, output_path):\n",
    "    user_ratings = data[data['user_id'] == user_id + 1][['user_id', 'movie_id', 'rating']]\n",
    "    predictions = generate_predictions_for_user(model, user_id, n_items)\n",
    "    predictions_df = pd.DataFrame(predictions, columns=['user_id', 'movie_id', 'predicted_rating'])\n",
    "    predictions_df['predicted_rating'] = predictions_df['predicted_rating'].round(2)\n",
    "    comparison_df = pd.merge(user_ratings, predictions_df, on=['user_id', 'movie_id'])\n",
    "    comparison_df.to_csv(output_path, index=False)\n",
    "    print(f\"Comparison CSV saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 100\n",
    "\n",
    "n_items = mf.n_items\n",
    "predictions = generate_predictions_for_user(mf, user_id, n_items)\n",
    "predictions_df = pd.DataFrame(predictions, columns=['user_id', 'movie_id', 'predicted_rating'])\n",
    "predictions_output_path = f'./data/output/predicted_ratings_user_{user_id}.csv'\n",
    "predictions_df.to_csv(predictions_output_path, index=False)\n",
    "print(f'Predicted ratings for user {user_id + 1} saved to {predictions_output_path}')\n",
    "\n",
    "comparison_output_path = f'./data/output/rating_comparison_user_{user_id}.csv'\n",
    "create_comparison_csv(mf, user_id, data, n_items, comparison_output_path)\n",
    "mf.export_latent_matrices_and_biases()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
