{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use matrix factorization for recommender system\n",
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 1,
>>>>>>> c682b41 (revert)
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parametter"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 2,
>>>>>>> c682b41 (revert)
   "metadata": {},
   "outputs": [],
   "source": [
    "K=60 # latent factors\n",
    "lam=0.02 # regularization\n",
    "learning_rate=0.001 # learning rate\n",
<<<<<<< HEAD
    "max_iter=20 # max iterations\n",
    "print_every=1 # print loss for each iteration\n",
    "batch_size=1000 # batch size\n",
=======
    "max_iter=30 # max iterations\n",
    "print_every=1 # print loss for each iteration\n",
>>>>>>> c682b41 (revert)
    "tolerance=1e-6 # tolerance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create class MF"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 3,
>>>>>>> c682b41 (revert)
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MFOptimized:\n",
<<<<<<< HEAD
    "    def __init__(self, Y, K, lam=0.1, learning_rate=0.01, max_iter=100, print_every=10, batch_size=1000, tolerance=1e-6):\n",
=======
    "    def __init__(self, Y, K, lam=0.1, learning_rate=0.01, max_iter=100, print_every=10, tolerance=1e-6):\n",
>>>>>>> c682b41 (revert)
    "        \"\"\"\n",
    "        Initialize the MF model.\n",
    "        Y: numpy array, shape (n_ratings, 3), each row [user_id, item_id, rating].\n",
    "        K: Number of latent factors.\n",
    "        lam: Regularization parameter.\n",
    "        learning_rate: Learning rate for gradient descent.\n",
    "        max_iter: Number of training iterations.\n",
    "        print_every: Print loss every `print_every` iterations.\n",
<<<<<<< HEAD
    "        batch_size: Size of mini-batches for SGD.\n",
=======
>>>>>>> c682b41 (revert)
    "        tolerance: Tolerance for convergence based on change in loss.\n",
    "        \"\"\"\n",
    "        self.Y = Y\n",
    "        self.K = K\n",
    "        self.lam = lam\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.print_every = print_every\n",
<<<<<<< HEAD
    "        self.batch_size = batch_size\n",
=======
>>>>>>> c682b41 (revert)
    "        self.tolerance = tolerance  # Tolerance for convergence\n",
    "\n",
    "        # Initialize user and item dimensions\n",
    "        self.n_users = int(np.max(Y[:, 0]) + 1)\n",
    "        self.n_items = int(np.max(Y[:, 1]) + 1)\n",
    "\n",
    "        # Initialize latent factors and biases\n",
    "        self.H = np.random.normal(0, 0.1, (self.n_users, K)).astype(np.float32)  # Latent factors for users\n",
    "        self.Q = np.random.normal(0, 0.1, (self.n_items, K)).astype(np.float32)  # Latent factors for items\n",
    "        self.o = np.zeros(self.n_users, dtype=np.float32)  # Biases for users\n",
    "        self.p = np.zeros(self.n_items, dtype=np.float32)  # Biases for items\n",
    "        self.mu = np.mean(Y[:, 2])  # Global average rating\n",
    "\n",
    "    def compute_loss(self):\n",
    "        \"\"\"\n",
    "        Compute the loss based on the provided formula.\n",
    "        \"\"\"\n",
    "        n_ratings = self.Y.shape[0]\n",
<<<<<<< HEAD
    "        indices = np.random.choice(n_ratings, self.batch_size, replace=False)\n",
    "        batch = self.Y[indices]\n",
    "\n",
    "        user_ids = batch[:, 0].astype(int)\n",
    "        item_ids = batch[:, 1].astype(int)\n",
    "        ratings = batch[:, 2]\n",
    "\n",
    "        # Calculate predictions\n",
    "        pred = self.o[user_ids] + self.p[item_ids] + self.mu + np.sum(self.H[user_ids] * self.Q[item_ids], axis=1)\n",
    "        \n",
    "        error = pred - ratings\n",
    "        loss = 0.5 * np.mean(error ** 2)\n",
    "\n",
    "        # Add regularization terms\n",
    "        loss += 0.5 * self.lam * (np.sum(self.H ** 2) + np.sum(self.Q ** 2))\n",
    "        loss += 0.5 * self.lam * np.sum(self.o ** 2)\n",
    "        loss += 0.5 * self.lam * np.sum(self.p ** 2)\n",
=======
    "        error_sum = 0\n",
    "        regularization_sum = 0\n",
    "\n",
    "        for n in range(n_ratings):\n",
    "            u, i, r = int(self.Y[n, 0]), int(self.Y[n, 1]), self.Y[n, 2]\n",
    "            pred = self.o[u] + self.p[i] + self.mu + np.dot(self.H[u], self.Q[i])\n",
    "            error = r - pred\n",
    "            error_sum += error ** 2\n",
    "            regularization_sum += np.sum(self.H[u] ** 2) + np.sum(self.Q[i] ** 2) + self.o[u] ** 2 + self.p[i] ** 2\n",
    "\n",
    "        # Compute total loss\n",
    "        loss = 0.5 * error_sum / n_ratings + 0.5 * self.lam * regularization_sum\n",
>>>>>>> c682b41 (revert)
    "        return loss\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
<<<<<<< HEAD
    "        Train the model using mini-batch stochastic gradient descent (SGD).\n",
    "        \"\"\"\n",
    "        prev_loss = float('inf')\n",
    "        \n",
    "        for it in range(self.max_iter):\n",
    "            n_ratings = self.Y.shape[0]\n",
    "            indices = np.arange(n_ratings)\n",
    "            np.random.shuffle(indices)\n",
    "\n",
    "            for i in range(0, n_ratings, self.batch_size):\n",
    "                batch_indices = indices[i:i + self.batch_size]\n",
    "                batch = self.Y[batch_indices]\n",
    "\n",
    "                user_ids = batch[:, 0].astype(int)\n",
    "                item_ids = batch[:, 1].astype(int)\n",
    "                ratings = batch[:, 2]\n",
    "\n",
    "                # Compute predictions\n",
    "                pred = self.o[user_ids] + self.p[item_ids] + self.mu + np.sum(self.H[user_ids] * self.Q[item_ids], axis=1)\n",
    "                error = pred - ratings\n",
    "\n",
    "                # Initialize gradients\n",
    "                grad_H = np.zeros_like(self.H)\n",
    "                grad_Q = np.zeros_like(self.Q)\n",
    "                grad_o = np.zeros_like(self.o)\n",
    "                grad_p = np.zeros_like(self.p)\n",
    "\n",
    "                # Compute gradients for each user-item pair in the batch\n",
    "                for u, i, r in zip(user_ids, item_ids, ratings):\n",
    "                    error_term = error[user_ids == u][0]  # The error term for this specific user-item pair\n",
    "                    \n",
    "                    # Update gradients for user and item latent factors\n",
    "                    grad_H[u] += error_term * self.Q[i]\n",
    "                    grad_Q[i] += error_term * self.H[u]\n",
    "                    \n",
    "                    # Update gradients for user and item biases\n",
    "                    grad_o[u] += error_term\n",
    "                    grad_p[i] += error_term\n",
    "\n",
    "                # Apply regularization to gradients\n",
    "                grad_H += self.lam * self.H\n",
    "                grad_Q += self.lam * self.Q\n",
    "                grad_o += self.lam * self.o\n",
    "                grad_p += self.lam * self.p\n",
    "\n",
    "                # Update parameters using np.add.at to handle duplicates in mini-batches\n",
    "                np.add.at(self.H, user_ids, -self.learning_rate * grad_H[user_ids])\n",
    "                np.add.at(self.Q, item_ids, -self.learning_rate * grad_Q[item_ids])\n",
    "                np.add.at(self.o, user_ids, -self.learning_rate * grad_o[user_ids])\n",
    "                np.add.at(self.p, item_ids, -self.learning_rate * grad_p[item_ids])\n",
=======
    "        Train the model using stochastic gradient descent (SGD).\n",
    "        \"\"\"\n",
    "        prev_loss = float('inf')\n",
    "\n",
    "        for it in range(self.max_iter):\n",
    "            np.random.shuffle(self.Y)  # Shuffle the data at the start of each epoch\n",
    "\n",
    "            for n in range(self.Y.shape[0]):\n",
    "                u, i, r = int(self.Y[n, 0]), int(self.Y[n, 1]), self.Y[n, 2]\n",
    "                \n",
    "                # Calculate prediction\n",
    "                pred = self.o[u] + self.p[i] + self.mu + np.dot(self.H[u], self.Q[i])\n",
    "\n",
    "                # Calculate error\n",
    "                error = r - pred\n",
    "\n",
    "                # Update latent factors and biases\n",
    "                self.H[u] += self.learning_rate * (error * self.Q[i] - self.lam * self.H[u])\n",
    "                self.Q[i] += self.learning_rate * (error * self.H[u] - self.lam * self.Q[i])\n",
    "\n",
    "                self.o[u] += self.learning_rate * (error - self.lam * self.o[u])\n",
    "                self.p[i] += self.learning_rate * (error - self.lam * self.p[i])\n",
>>>>>>> c682b41 (revert)
    "\n",
    "            # Compute current loss and check for convergence\n",
    "            loss = self.compute_loss()\n",
    "\n",
    "            # Check if the change in loss is smaller than the tolerance\n",
    "            if abs(prev_loss - loss) < self.tolerance:\n",
    "                print(f\"Convergence reached at iteration {it + 1}\")\n",
    "                break\n",
    "\n",
    "            prev_loss = loss\n",
    "\n",
    "            # Print loss every 'print_every' iterations\n",
    "            if (it + 1) % self.print_every == 0:\n",
    "                print(f\"Iteration {it + 1}/{self.max_iter}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict(self, u, i):\n",
    "        \"\"\"\n",
    "        Predict the rating for a specific user-item pair.\n",
    "        \"\"\"\n",
    "        u, i = int(u), int(i)\n",
    "        pred = self.o[u] + self.p[i] + self.mu + np.dot(self.H[u], self.Q[i])\n",
    "        return np.clip(pred, 0, 5)\n",
    "\n",
    "    def evaluate_rmse(self, test_data):\n",
    "        \"\"\"\n",
    "        Compute RMSE on the test set.\n",
    "        \"\"\"\n",
    "        n_tests = test_data.shape[0]\n",
    "        squared_error = 0\n",
    "        for n in range(n_tests):\n",
    "            pred = self.predict(test_data[n, 0], test_data[n, 1])\n",
    "            squared_error += (pred - test_data[n, 2]) ** 2\n",
    "        rmse = np.sqrt(squared_error / n_tests)\n",
    "        return rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the results\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 4,
>>>>>>> c682b41 (revert)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Iteration 1/20, Loss: 1166.3543\n",
      "Iteration 2/20, Loss: 1166.4425\n",
      "Iteration 3/20, Loss: 1166.5765\n",
      "Iteration 4/20, Loss: 1166.5800\n",
      "Iteration 5/20, Loss: 1166.7403\n",
      "Iteration 6/20, Loss: 1166.8071\n",
      "Iteration 7/20, Loss: 1166.8683\n",
      "Iteration 8/20, Loss: 1166.8941\n",
      "Iteration 9/20, Loss: 1166.8294\n",
      "Iteration 10/20, Loss: 1166.9319\n",
      "Iteration 11/20, Loss: 1166.9864\n",
      "Iteration 12/20, Loss: 1167.0069\n",
      "Iteration 13/20, Loss: 1167.0579\n",
      "Iteration 14/20, Loss: 1167.0511\n",
      "Iteration 15/20, Loss: 1167.1286\n",
      "Iteration 16/20, Loss: 1167.1216\n",
      "Iteration 17/20, Loss: 1167.1643\n",
      "Iteration 18/20, Loss: 1167.2084\n",
      "Iteration 19/20, Loss: 1167.2029\n",
      "Iteration 20/20, Loss: 1167.2086\n",
      "\n",
      "Optimized MF, RMSE: 0.9337\n"
=======
      "Iteration 1/30, Loss: 988.7343\n",
      "Iteration 2/30, Loss: 1000.8620\n",
      "Iteration 3/30, Loss: 1008.1942\n",
      "Iteration 4/30, Loss: 1011.9205\n",
      "Iteration 5/30, Loss: 1015.5693\n",
      "Iteration 6/30, Loss: 1017.6021\n",
      "Iteration 7/30, Loss: 1018.5954\n",
      "Iteration 8/30, Loss: 1020.8646\n",
      "Iteration 9/30, Loss: 1022.8664\n",
      "Iteration 10/30, Loss: 1024.5572\n",
      "Iteration 11/30, Loss: 1025.6610\n",
      "Iteration 12/30, Loss: 1027.4301\n",
      "Iteration 13/30, Loss: 1030.3096\n",
      "Iteration 14/30, Loss: 1031.4924\n",
      "Iteration 15/30, Loss: 1034.4980\n",
      "Iteration 16/30, Loss: 1036.6740\n",
      "Iteration 17/30, Loss: 1039.9486\n",
      "Iteration 18/30, Loss: 1042.2191\n",
      "Iteration 19/30, Loss: 1045.9796\n",
      "Iteration 20/30, Loss: 1049.2792\n",
      "Iteration 21/30, Loss: 1054.0804\n",
      "Iteration 22/30, Loss: 1057.8140\n",
      "Iteration 23/30, Loss: 1062.4488\n",
      "Iteration 24/30, Loss: 1066.8656\n",
      "Iteration 25/30, Loss: 1071.3400\n",
      "Iteration 26/30, Loss: 1076.6589\n",
      "Iteration 27/30, Loss: 1082.5284\n",
      "Iteration 28/30, Loss: 1087.5548\n",
      "Iteration 29/30, Loss: 1093.2440\n",
      "Iteration 30/30, Loss: 1099.9081\n",
      "\n",
      "Optimized MF, RMSE: 0.8976\n"
>>>>>>> c682b41 (revert)
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_path = '../data/ml-latest-small/ratings.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "data = data.rename(columns={'userId': 'user_id', 'movieId': 'movie_id'})\n",
    "data = data[['user_id', 'movie_id', 'rating']]\n",
    "\n",
    "# Split data into train and test\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "rate_train = train_data.to_numpy()\n",
    "rate_test = test_data.to_numpy()\n",
    "\n",
    "# Adjust indices to be 0-based\n",
    "rate_train[:, :2] -= 1\n",
    "rate_test[:, :2] -= 1\n",
    "\n",
    "# Train the model\n",
<<<<<<< HEAD
    "mf = MFOptimized(rate_train, K, lam, learning_rate, max_iter, print_every, batch_size, tolerance)\n",
=======
    "mf = MFOptimized(rate_train, K, lam, learning_rate, max_iter, print_every, tolerance)\n",
>>>>>>> c682b41 (revert)
    "mf.fit()\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = mf.evaluate_rmse(rate_test)\n",
    "print(f\"\\nOptimized MF, RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
=======
    "Save the latent matrices and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save H (user latent factors) to CSV\n",
    "H_df = pd.DataFrame(mf.H)\n",
    "H_df.to_csv('./data/output/user_latent_factors.csv', index=False)\n",
    "\n",
    "# Save Q (item latent factors) to CSV\n",
    "Q_df = pd.DataFrame(mf.Q)\n",
    "Q_df.to_csv('./data/output/item_latent_factors.csv', index=False)\n",
    "\n",
    "# Save user biases (o) to CSV\n",
    "o_df = pd.DataFrame(mf.o, columns=[\"bias\"])\n",
    "o_df.to_csv('./data/output/user_biases.csv', index=False)\n",
    "\n",
    "# Save item biases (p) to CSV\n",
    "p_df = pd.DataFrame(mf.p, columns=[\"bias\"])\n",
    "p_df.to_csv('./data/output/item_biases.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
>>>>>>> c682b41 (revert)
    "Generate a prediction for a user"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 11,
>>>>>>> c682b41 (revert)
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions_for_user(model, user_id, n_items):\n",
    "    predictions = [(user_id + 1, item + 1, model.predict(user_id, item)) for item in range(n_items)]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make comparision of real ratings and model's predicted ratings for a user"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 12,
>>>>>>> c682b41 (revert)
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_csv(model, user_id, data, n_items, output_path):\n",
    "    user_ratings = data[data['user_id'] == user_id + 1][['user_id', 'movie_id', 'rating']]\n",
    "    predictions = generate_predictions_for_user(model, user_id, n_items)\n",
    "    predictions_df = pd.DataFrame(predictions, columns=['user_id', 'movie_id', 'predicted_rating'])\n",
    "    predictions_df['predicted_rating'] = predictions_df['predicted_rating'].round(2)\n",
    "    comparison_df = pd.merge(user_ratings, predictions_df, on=['user_id', 'movie_id'])\n",
    "    comparison_df.to_csv(output_path, index=False)\n",
    "    print(f\"Comparison CSV saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "Test it"
=======
    "Predict for a random user"
>>>>>>> c682b41 (revert)
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": 13,
>>>>>>> c682b41 (revert)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Predicted ratings for user 101 saved to ./data/output/predicted_ratings_user_100.csv\n",
      "Comparison CSV saved to ./data/output/rating_comparison_user_100.csv\n"
=======
      "Predicted ratings for user 101 saved to ./data/output/pred/predicted_ratings_user_100.csv\n",
      "Comparison CSV saved to ./data/output/pred/rating_comparison_user_100.csv\n"
>>>>>>> c682b41 (revert)
     ]
    }
   ],
   "source": [
    "user_id = 100\n",
    "\n",
    "n_items = mf.n_items\n",
    "predictions = generate_predictions_for_user(mf, user_id, n_items)\n",
    "predictions_df = pd.DataFrame(predictions, columns=['user_id', 'movie_id', 'predicted_rating'])\n",
<<<<<<< HEAD
    "predictions_output_path = f'./data/output/predicted_ratings_user_{user_id}.csv'\n",
    "predictions_df.to_csv(predictions_output_path, index=False)\n",
    "print(f'Predicted ratings for user {user_id + 1} saved to {predictions_output_path}')\n",
    "\n",
    "comparison_output_path = f'./data/output/rating_comparison_user_{user_id}.csv'\n",
    "create_comparison_csv(mf, user_id, data, n_items, comparison_output_path)"
=======
    "predictions_output_path = f'./data/output/pred/predicted_ratings_user_{user_id}.csv'\n",
    "predictions_df.to_csv(predictions_output_path, index=False)\n",
    "print(f'Predicted ratings for user {user_id + 1} saved to {predictions_output_path}')\n",
    "comparison_output_path = f'./data/output/pred/rating_comparison_user_{user_id}.csv'\n",
    "create_comparison_csv(mf, user_id, data, n_items, comparison_output_path)\n"
>>>>>>> c682b41 (revert)
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
