{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use matrix factorization for recommender system\n",
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parametter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=60 # latent factors\n",
    "lam=0.02 # regularization\n",
    "learning_rate=0.001 # learning rate\n",
    "max_iter=20 # max iterations\n",
    "print_every=1 # print loss for each iteration\n",
    "batch_size=1000 # batch size\n",
    "tolerance=1e-6 # tolerance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create class MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MFOptimized:\n",
    "    def __init__(self, Y, K, lam=0.1, learning_rate=0.01, max_iter=100, print_every=10, tolerance=1e-6):\n",
    "        \"\"\"\n",
    "        Initialize the MF model.\n",
    "        Y: numpy array, shape (n_ratings, 3), each row [user_id, item_id, rating].\n",
    "        K: Number of latent factors.\n",
    "        lam: Regularization parameter.\n",
    "        learning_rate: Learning rate for gradient descent.\n",
    "        max_iter: Number of training iterations.\n",
    "        print_every: Print loss every print_every iterations.\n",
    "        tolerance: Tolerance for convergence based on change in loss.\n",
    "        \"\"\"\n",
    "        self.Y = Y\n",
    "        self.K = K\n",
    "        self.lam = lam\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.print_every = print_every\n",
    "        self.tolerance = tolerance  # Tolerance for convergence\n",
    "\n",
    "        # Initialize user and item dimensions\n",
    "        self.n_users = int(np.max(Y[:, 0]) + 1)\n",
    "        self.n_items = int(np.max(Y[:, 1]) + 1)\n",
    "\n",
    "        # Initialize latent factors and biases\n",
    "        self.H = np.random.normal(0, 0.1, (self.n_users, K)).astype(np.float32)  # Latent factors for users\n",
    "        self.Q = np.random.normal(0, 0.1, (self.n_items, K)).astype(np.float32)  # Latent factors for items\n",
    "        self.o = np.zeros(self.n_users, dtype=np.float32)  # Biases for users\n",
    "        self.p = np.zeros(self.n_items, dtype=np.float32)  # Biases for items\n",
    "        self.mu = np.mean(Y[:, 2])  # Global average rating\n",
    "\n",
    "    def compute_loss(self):\n",
    "        \"\"\"\n",
    "        Compute the loss based on the provided formula.\n",
    "        \"\"\"\n",
    "        n_ratings = self.Y.shape[0]\n",
    "        error_sum = 0\n",
    "        regularization_sum = 0\n",
    "\n",
    "        for n in range(n_ratings):\n",
    "            u, i, r = int(self.Y[n, 0]), int(self.Y[n, 1]), self.Y[n, 2]\n",
    "            pred = self.o[u] + self.p[i] + self.mu + np.dot(self.H[u], self.Q[i])\n",
    "            error = r - pred\n",
    "            error_sum += error ** 2\n",
    "            regularization_sum += np.sum(self.H[u] ** 2) + np.sum(self.Q[i] ** 2) + self.o[u] ** 2 + self.p[i] ** 2\n",
    "\n",
    "        # Compute total loss\n",
    "        loss = 0.5 * error_sum / n_ratings + 0.5 * self.lam * regularization_sum\n",
    "        return loss\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Train the model using stochastic gradient descent (SGD).\n",
    "        \"\"\"\n",
    "        prev_loss = float('inf')\n",
    "\n",
    "        for it in range(self.max_iter):\n",
    "            np.random.shuffle(self.Y)  # Shuffle the data at the start of each epoch\n",
    "\n",
    "            for n in range(self.Y.shape[0]):\n",
    "                u, i, r = int(self.Y[n, 0]), int(self.Y[n, 1]), self.Y[n, 2]\n",
    "                \n",
    "                # Calculate prediction\n",
    "                pred = self.o[u] + self.p[i] + self.mu + np.dot(self.H[u], self.Q[i])\n",
    "\n",
    "                # Calculate error\n",
    "                error = r - pred\n",
    "\n",
    "                # Update latent factors and biases\n",
    "                self.H[u] += self.learning_rate * (error * self.Q[i] - self.lam * self.H[u])\n",
    "                self.Q[i] += self.learning_rate * (error * self.H[u] - self.lam * self.Q[i])\n",
    "\n",
    "                self.o[u] += self.learning_rate * (error - self.lam * self.o[u])\n",
    "                self.p[i] += self.learning_rate * (error - self.lam * self.p[i])\n",
    "\n",
    "            # Compute current loss and check for convergence\n",
    "            loss = self.compute_loss()\n",
    "\n",
    "            # Check if the change in loss is smaller than the tolerance\n",
    "            if abs(prev_loss - loss) < self.tolerance:\n",
    "                print(f\"Convergence reached at iteration {it + 1}\")\n",
    "                break\n",
    "\n",
    "            prev_loss = loss\n",
    "\n",
    "            # Print loss every 'print_every' iterations\n",
    "            if (it + 1) % self.print_every == 0:\n",
    "                print(f\"Iteration {it + 1}/{self.max_iter}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict(self, u, i):\n",
    "        \"\"\"\n",
    "        Predict the rating for a specific user-item pair.\n",
    "        \"\"\"\n",
    "        u, i = int(u), int(i)\n",
    "        pred = self.o[u] + self.p[i] + self.mu + np.dot(self.H[u], self.Q[i])\n",
    "        return np.clip(pred, 0, 5)\n",
    "\n",
    "    def evaluate_rmse(self, test_data):\n",
    "        \"\"\"\n",
    "        Compute RMSE on the test set.\n",
    "        \"\"\"\n",
    "        n_tests = test_data.shape[0]\n",
    "        squared_error = 0\n",
    "        for n in range(n_tests):\n",
    "            pred = self.predict(test_data[n, 0], test_data[n, 1])\n",
    "            squared_error += (pred - test_data[n, 2]) ** 2\n",
    "        rmse = np.sqrt(squared_error / n_tests)\n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the results\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/20, Loss: 1166.3543\n",
      "Iteration 2/20, Loss: 1166.4425\n",
      "Iteration 3/20, Loss: 1166.5765\n",
      "Iteration 4/20, Loss: 1166.5800\n",
      "Iteration 5/20, Loss: 1166.7403\n",
      "Iteration 6/20, Loss: 1166.8071\n",
      "Iteration 7/20, Loss: 1166.8683\n",
      "Iteration 8/20, Loss: 1166.8941\n",
      "Iteration 9/20, Loss: 1166.8294\n",
      "Iteration 10/20, Loss: 1166.9319\n",
      "Iteration 11/20, Loss: 1166.9864\n",
      "Iteration 12/20, Loss: 1167.0069\n",
      "Iteration 13/20, Loss: 1167.0579\n",
      "Iteration 14/20, Loss: 1167.0511\n",
      "Iteration 15/20, Loss: 1167.1286\n",
      "Iteration 16/20, Loss: 1167.1216\n",
      "Iteration 17/20, Loss: 1167.1643\n",
      "Iteration 18/20, Loss: 1167.2084\n",
      "Iteration 19/20, Loss: 1167.2029\n",
      "Iteration 20/20, Loss: 1167.2086\n",
      "\n",
      "Optimized MF, RMSE: 0.9337\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_path = '../data/ml-latest-small/ratings.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "data = data.rename(columns={'userId': 'user_id', 'movieId': 'movie_id'})\n",
    "data = data[['user_id', 'movie_id', 'rating']]\n",
    "\n",
    "# Split data into train and test\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "rate_train = train_data.to_numpy()\n",
    "rate_test = test_data.to_numpy()\n",
    "\n",
    "# Adjust indices to be 0-based\n",
    "rate_train[:, :2] -= 1\n",
    "rate_test[:, :2] -= 1\n",
    "\n",
    "# Train the model\n",
    "mf = MFOptimized(rate_train, K, lam, learning_rate, max_iter, print_every, batch_size, tolerance)\n",
    "mf.fit()\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = mf.evaluate_rmse(rate_test)\n",
    "print(f\"\\nOptimized MF, RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a prediction for a user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions_for_user(model, user_id, n_items):\n",
    "    predictions = [(user_id + 1, item + 1, model.predict(user_id, item)) for item in range(n_items)]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make comparision of real ratings and model's predicted ratings for a user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_csv(model, user_id, data, n_items, output_path):\n",
    "    user_ratings = data[data['user_id'] == user_id + 1][['user_id', 'movie_id', 'rating']]\n",
    "    predictions = generate_predictions_for_user(model, user_id, n_items)\n",
    "    predictions_df = pd.DataFrame(predictions, columns=['user_id', 'movie_id', 'predicted_rating'])\n",
    "    predictions_df['predicted_rating'] = predictions_df['predicted_rating'].round(2)\n",
    "    comparison_df = pd.merge(user_ratings, predictions_df, on=['user_id', 'movie_id'])\n",
    "    comparison_df.to_csv(output_path, index=False)\n",
    "    print(f\"Comparison CSV saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted ratings for user 101 saved to ./data/output/predicted_ratings_user_100.csv\n",
      "Comparison CSV saved to ./data/output/rating_comparison_user_100.csv\n"
     ]
    }
   ],
   "source": [
    "user_id = 100\n",
    "\n",
    "n_items = mf.n_items\n",
    "predictions = generate_predictions_for_user(mf, user_id, n_items)\n",
    "predictions_df = pd.DataFrame(predictions, columns=['user_id', 'movie_id', 'predicted_rating'])\n",
    "predictions_output_path = f'./data/output/predicted_ratings_user_{user_id}.csv'\n",
    "predictions_df.to_csv(predictions_output_path, index=False)\n",
    "print(f'Predicted ratings for user {user_id + 1} saved to {predictions_output_path}')\n",
    "\n",
    "comparison_output_path = f'./data/output/rating_comparison_user_{user_id}.csv'\n",
    "create_comparison_csv(mf, user_id, data, n_items, comparison_output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
