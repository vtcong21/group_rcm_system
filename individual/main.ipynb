{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use matrix factorization for recommender system\n",
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parametter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=60 # latent factors\n",
    "lam=0.02 # regularization\n",
    "learning_rate=0.001 # learning rate\n",
    "max_iter=20 # max iterations\n",
    "print_every=1 # print loss for each iteration\n",
    "batch_size=1000 # batch size\n",
    "tolerance=1e-6 # tolerance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create class MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MFOptimized:\n",
    "    def __init__(self, Y, K, lam=0.1, learning_rate=0.01, max_iter=100, print_every=10, batch_size=1000, tolerance=1e-6):\n",
    "        \"\"\"\n",
    "        Initialize the MF model.\n",
    "        Y: numpy array, shape (n_ratings, 3), each row [user_id, item_id, rating].\n",
    "        K: Number of latent factors.\n",
    "        lam: Regularization parameter.\n",
    "        learning_rate: Learning rate for gradient descent.\n",
    "        max_iter: Number of training iterations.\n",
    "        print_every: Print loss every `print_every` iterations.\n",
    "        batch_size: Size of mini-batches for SGD.\n",
    "        tolerance: Tolerance for convergence based on change in loss.\n",
    "        \"\"\"\n",
    "        self.Y = Y\n",
    "        self.K = K\n",
    "        self.lam = lam\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.print_every = print_every\n",
    "        self.batch_size = batch_size\n",
    "        self.tolerance = tolerance  # Tolerance for convergence\n",
    "\n",
    "        # Initialize user and item dimensions\n",
    "        self.n_users = int(np.max(Y[:, 0]) + 1)\n",
    "        self.n_items = int(np.max(Y[:, 1]) + 1)\n",
    "\n",
    "        # Initialize latent factors and biases\n",
    "        self.H = np.random.normal(0, 0.1, (self.n_users, K)).astype(np.float32)  # Latent factors for users\n",
    "        self.Q = np.random.normal(0, 0.1, (self.n_items, K)).astype(np.float32)  # Latent factors for items\n",
    "        self.o = np.zeros(self.n_users, dtype=np.float32)  # Biases for users\n",
    "        self.p = np.zeros(self.n_items, dtype=np.float32)  # Biases for items\n",
    "        self.mu = np.mean(Y[:, 2])  # Global average rating\n",
    "\n",
    "    def compute_loss(self):\n",
    "        \"\"\"\n",
    "        Compute the loss based on the provided formula.\n",
    "        \"\"\"\n",
    "        n_ratings = self.Y.shape[0]\n",
    "        indices = np.random.choice(n_ratings, self.batch_size, replace=False)\n",
    "        batch = self.Y[indices]\n",
    "\n",
    "        user_ids = batch[:, 0].astype(int)\n",
    "        item_ids = batch[:, 1].astype(int)\n",
    "        ratings = batch[:, 2]\n",
    "\n",
    "        # Calculate predictions\n",
    "        pred = self.o[user_ids] + self.p[item_ids] + self.mu + np.sum(self.H[user_ids] * self.Q[item_ids], axis=1)\n",
    "        \n",
    "        error = pred - ratings\n",
    "        loss = 0.5 * np.mean(error ** 2)\n",
    "\n",
    "        # Add regularization terms\n",
    "        loss += 0.5 * self.lam * (np.sum(self.H ** 2) + np.sum(self.Q ** 2))\n",
    "        loss += 0.5 * self.lam * np.sum(self.o ** 2)\n",
    "        loss += 0.5 * self.lam * np.sum(self.p ** 2)\n",
    "        return loss\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Train the model using mini-batch stochastic gradient descent (SGD).\n",
    "        \"\"\"\n",
    "        prev_loss = float('inf')\n",
    "        \n",
    "        for it in range(self.max_iter):\n",
    "            n_ratings = self.Y.shape[0]\n",
    "            indices = np.arange(n_ratings)\n",
    "            np.random.shuffle(indices)\n",
    "\n",
    "            for i in range(0, n_ratings, self.batch_size):\n",
    "                batch_indices = indices[i:i + self.batch_size]\n",
    "                batch = self.Y[batch_indices]\n",
    "\n",
    "                user_ids = batch[:, 0].astype(int)\n",
    "                item_ids = batch[:, 1].astype(int)\n",
    "                ratings = batch[:, 2]\n",
    "\n",
    "                # Compute predictions\n",
    "                pred = self.o[user_ids] + self.p[item_ids] + self.mu + np.sum(self.H[user_ids] * self.Q[item_ids], axis=1)\n",
    "                error = pred - ratings\n",
    "\n",
    "                # Initialize gradients\n",
    "                grad_H = np.zeros_like(self.H)\n",
    "                grad_Q = np.zeros_like(self.Q)\n",
    "                grad_o = np.zeros_like(self.o)\n",
    "                grad_p = np.zeros_like(self.p)\n",
    "\n",
    "                # Compute gradients for each user-item pair in the batch\n",
    "                for u, i, r in zip(user_ids, item_ids, ratings):\n",
    "                    error_term = error[user_ids == u][0]  # The error term for this specific user-item pair\n",
    "                    \n",
    "                    # Update gradients for user and item latent factors\n",
    "                    grad_H[u] += error_term * self.Q[i]\n",
    "                    grad_Q[i] += error_term * self.H[u]\n",
    "                    \n",
    "                    # Update gradients for user and item biases\n",
    "                    grad_o[u] += error_term\n",
    "                    grad_p[i] += error_term\n",
    "\n",
    "                # Apply regularization to gradients\n",
    "                grad_H += self.lam * self.H\n",
    "                grad_Q += self.lam * self.Q\n",
    "                grad_o += self.lam * self.o\n",
    "                grad_p += self.lam * self.p\n",
    "\n",
    "                # Update parameters using np.add.at to handle duplicates in mini-batches\n",
    "                np.add.at(self.H, user_ids, -self.learning_rate * grad_H[user_ids])\n",
    "                np.add.at(self.Q, item_ids, -self.learning_rate * grad_Q[item_ids])\n",
    "                np.add.at(self.o, user_ids, -self.learning_rate * grad_o[user_ids])\n",
    "                np.add.at(self.p, item_ids, -self.learning_rate * grad_p[item_ids])\n",
    "\n",
    "            # Compute current loss and check for convergence\n",
    "            loss = self.compute_loss()\n",
    "\n",
    "            # Check if the change in loss is smaller than the tolerance\n",
    "            if abs(prev_loss - loss) < self.tolerance:\n",
    "                print(f\"Convergence reached at iteration {it + 1}\")\n",
    "                break\n",
    "\n",
    "            prev_loss = loss\n",
    "\n",
    "            # Print loss every 'print_every' iterations\n",
    "            if (it + 1) % self.print_every == 0:\n",
    "                print(f\"Iteration {it + 1}/{self.max_iter}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict(self, u, i):\n",
    "        \"\"\"\n",
    "        Predict the rating for a specific user-item pair.\n",
    "        \"\"\"\n",
    "        u, i = int(u), int(i)\n",
    "        pred = self.o[u] + self.p[i] + self.mu + np.dot(self.H[u], self.Q[i])\n",
    "        return np.clip(pred, 0, 5)\n",
    "\n",
    "    def evaluate_rmse(self, test_data):\n",
    "        \"\"\"\n",
    "        Compute RMSE on the test set.\n",
    "        \"\"\"\n",
    "        n_tests = test_data.shape[0]\n",
    "        squared_error = 0\n",
    "        for n in range(n_tests):\n",
    "            pred = self.predict(test_data[n, 0], test_data[n, 1])\n",
    "            squared_error += (pred - test_data[n, 2]) ** 2\n",
    "        rmse = np.sqrt(squared_error / n_tests)\n",
    "        return rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the results\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/20, Loss: 1166.2212\n",
      "Iteration 2/20, Loss: 1166.2885\n",
      "Iteration 3/20, Loss: 1166.4358\n",
      "Iteration 4/20, Loss: 1166.4878\n",
      "Iteration 5/20, Loss: 1166.5428\n",
      "Iteration 6/20, Loss: 1166.6224\n",
      "Iteration 7/20, Loss: 1166.7377\n",
      "Iteration 8/20, Loss: 1166.6724\n",
      "Iteration 9/20, Loss: 1166.7292\n",
      "Iteration 10/20, Loss: 1166.7745\n",
      "Iteration 11/20, Loss: 1166.7675\n",
      "Iteration 12/20, Loss: 1166.8196\n",
      "Iteration 13/20, Loss: 1166.8366\n",
      "Iteration 14/20, Loss: 1166.9293\n",
      "Iteration 15/20, Loss: 1166.9045\n",
      "Iteration 16/20, Loss: 1166.9760\n",
      "Iteration 17/20, Loss: 1166.9934\n",
      "Iteration 18/20, Loss: 1167.1477\n",
      "Iteration 19/20, Loss: 1167.0711\n",
      "Iteration 20/20, Loss: 1167.1373\n",
      "\n",
      "Optimized MF, RMSE: 0.9415\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_path = '../data/ml-latest-small/ratings.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "data = data.rename(columns={'userId': 'user_id', 'movieId': 'movie_id'})\n",
    "data = data[['user_id', 'movie_id', 'rating']]\n",
    "\n",
    "# Split data into train and test\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "rate_train = train_data.to_numpy()\n",
    "rate_test = test_data.to_numpy()\n",
    "\n",
    "# Adjust indices to be 0-based\n",
    "rate_train[:, :2] -= 1\n",
    "rate_test[:, :2] -= 1\n",
    "\n",
    "# Train the model\n",
    "mf = MFOptimized(rate_train, K, lam, learning_rate, max_iter, print_every, batch_size, tolerance)\n",
    "mf.fit()\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = mf.evaluate_rmse(rate_test)\n",
    "print(f\"\\nOptimized MF, RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a prediction for a user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions_for_user(model, user_id, n_items):\n",
    "    predictions = [(user_id + 1, item + 1, model.predict(user_id, item)) for item in range(n_items)]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make comparision of real ratings and model's predicted ratings for a user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_csv(model, user_id, data, n_items, output_path):\n",
    "    user_ratings = data[data['user_id'] == user_id + 1][['user_id', 'movie_id', 'rating']]\n",
    "    predictions = generate_predictions_for_user(model, user_id, n_items)\n",
    "    predictions_df = pd.DataFrame(predictions, columns=['user_id', 'movie_id', 'predicted_rating'])\n",
    "    comparison_df = pd.merge(user_ratings, predictions_df, on=['user_id', 'movie_id'])\n",
    "    comparison_df.to_csv(output_path, index=False)\n",
    "    print(f\"Comparison CSV saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted ratings for user 1 saved to ./data/output/predicted_ratings_user_0.csv\n",
      "Comparison CSV saved to ./data/output/rating_comparison_user_0.csv\n"
     ]
    }
   ],
   "source": [
    "user_id = 0\n",
    "n_items = mf.n_items\n",
    "predictions = generate_predictions_for_user(mf, user_id, n_items)\n",
    "predictions_df = pd.DataFrame(predictions, columns=['user_id', 'movie_id', 'predicted_rating'])\n",
    "predictions_output_path = f'./data/output/predicted_ratings_user_{user_id}.csv'\n",
    "predictions_df.to_csv(predictions_output_path, index=False)\n",
    "print(f'Predicted ratings for user {user_id + 1} saved to {predictions_output_path}')\n",
    "\n",
    "comparison_output_path = f'./data/output/rating_comparison_user_{user_id}.csv'\n",
    "create_comparison_csv(mf, user_id, data, n_items, comparison_output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
